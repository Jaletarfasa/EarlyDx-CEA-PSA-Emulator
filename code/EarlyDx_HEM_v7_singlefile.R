
############################################################
# December 19, 2025
# Early Diagnosis HE Model – SINGLE-FILE Script (v7.0)
# Decision-analytic CEA + PSA (Monte Carlo) + R-ONLY ML Emulator
#
# What’s new in v7.0 (R-only):
#  (D) Emulator dataset generator (outer-loop scenarios)
#  (E) Emulator training in R (xgboost) for dC_mean, dQ_mean, p_ce
#  (F) Emulator prediction function (instant what-if)
#  (G) Optional Plumber API endpoint (still single-file)
#
# Your original LOCKDOWN FIXES retained:
#  (A) RNG locked + seed fixed + seed reset before PSA
#  (B) Run settings locked and written to audit
#  (C) ICER_mean locked: ratio-of-means headline + mean-of-ratios reported
#
# Notes:
# - This script uses SYNTHETIC simulation data generated by the model itself.
# - Emulator targets are stable (dC_mean, dQ_mean, p_ce). ICER is derived.
# - If you want faster dataset generation, reduce N_PATIENTS/PSA_ITERS in
#   emulator generation only (see EMULATOR_SPEED section).
############################################################

# =============================
# 0) Setup
# =============================
suppressPackageStartupMessages({
  library(stats)
  library(ggplot2)
  library(dplyr)
  library(survival)   # KM curves
  library(cowplot)    # optional composite figures
})

theme_set(theme_minimal(base_size = 13))

# ---- RNG LOCKDOWN (A) ----
RNGkind(kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")
SEED_FIXED <- 123
set.seed(SEED_FIXED)

# Output folder
OUTDIR <- file.path(getwd(), "earlydx_outputs")
if (!dir.exists(OUTDIR)) dir.create(OUTDIR, recursive = TRUE)

# Helper to save a small text log
log_path <- file.path(OUTDIR, "run_log.txt")
log_line <- function(...) cat(..., "\n", file = log_path, append = TRUE)

log_line("=== EarlyDx CEA+PSA run log ===")
log_line(format(Sys.time(), "%Y-%m-%d %H:%M:%S"))
log_line(paste0("Seed fixed: ", SEED_FIXED))
log_line(paste0("R version: ", R.version.string))

# =============================
# 0.1) Toggles (run what you want)
# =============================
RUN_PSA_MAIN              <- FALSE     # run your core PSA + plots
RUN_EMULATOR_DATASET      <- FALSE    # generate emulator_training.csv (outer-loop scenarios)
RUN_EMULATOR_TRAIN        <- FALSE    # train xgboost emulator models and save .rds
RUN_EMULATOR_DEMO_PREDICT <- TRUE    # demo a single emulator prediction
RUN_PLUMBER_API           <- FALSE    # run local API /predict (blocks session)

# =============================
# 1) Helpers
# =============================
beta_params_from_mean_sd <- function(mean, sd){
  if (!is.numeric(mean) || !is.numeric(sd)) stop("mean/sd must be numeric.")
  if (mean <= 0 || mean >= 1) stop("Beta mean must be in (0,1).")
  if (sd <= 0) stop("Beta SD must be > 0.")
  var <- sd^2
  max_var <- mean*(1-mean)
  if (var >= max_var) stop("Beta infeasible: var >= mean*(1-mean). Reduce SD.")
  tmp <- mean*(1-mean)/var - 1
  alpha <- mean*tmp
  beta  <- (1-mean)*tmp
  if (alpha <= 0 || beta <= 0) stop("Invalid Beta params computed; check mean/SD.")
  c(alpha=alpha, beta=beta)
}

exp_rate_from_mean <- function(mean){
  if (mean <= 0) stop("Exponential mean must be > 0.")
  1/mean
}

rnorm_trunc0 <- function(n, mean, sd){
  if (sd < 0) stop("SD must be >= 0.")
  pmax(0, rnorm(n, mean=mean, sd=sd))
}

mcse_mean <- function(x) sd(x)/sqrt(length(x))

weibull_mean <- function(shape, scale) scale * gamma(1 + 1/shape)

# Discounting
discounted_ly <- function(T, r){
  if (r <= 0) return(T)
  (1 - exp(-r*T))/r
}
discount_midpoint <- function(total, T, r){
  total * exp(-r*(T/2))
}

q_safe <- function(x, p) unname(as.numeric(stats::quantile(x, p, na.rm = TRUE)))

# =============================
# 2) Inputs (LOCKED run settings) (B)
# =============================
N_PATIENTS <- 1000
PSA_ITERS  <- 2000
WTP        <- 20000
DISC_RATE  <- 0.035  # 3.5%/yr

# Stage probabilities
p_std_mean <- 0.60
p_std_sd   <- 0.10 * p_std_mean  # 0.06
p_int_mean <- 0.70
p_int_sd   <- 0.10 * p_int_mean  # 0.07

# Survival (Weibull)
#shape_E <- 1.2; scale_E <- 0.06
#shape_L <- 0.5; scale_L <- 0.5

# Survival (Weibull) — FIXED so Early > Late
shape_E <- 1.2; scale_E <- 1.5
shape_L <- 0.5; scale_L <- 0.6


# Costs (Normal SD=20% mean, truncated at 0)
mu_E <- 1000 + 6500 + 2000   # £9,500
mu_L <- 1000 + 12000 + 6000  # £19,000
sd_E <- 0.20 * mu_E
sd_L <- 0.20 * mu_L

cost_intervention_fixed <- 500  # fixed per patient, assumed upfront (no discount)

# QALYs (toy Exponential)
qaly_E_mean <- 4.0
qaly_L_mean <- 1.25

# Save audit trail
inputs_audit <- data.frame(
  name = c("SEED_FIXED","N_PATIENTS","PSA_ITERS","WTP","DISC_RATE",
           "p_std_mean","p_std_sd","p_int_mean","p_int_sd",
           "shape_E","scale_E","shape_L","scale_L",
           "mu_E","sd_E","mu_L","sd_L",
           "cost_intervention_fixed","qaly_E_mean","qaly_L_mean"),
  value = c(SEED_FIXED,N_PATIENTS,PSA_ITERS,WTP,DISC_RATE,
            p_std_mean,p_std_sd,p_int_mean,p_int_sd,
            shape_E,scale_E,shape_L,scale_L,
            mu_E,sd_E,mu_L,sd_L,
            cost_intervention_fixed,qaly_E_mean,qaly_L_mean)
)
write.csv(inputs_audit, file.path(OUTDIR,"inputs_audit.csv"), row.names=FALSE)

# =============================
# 3) CHECKS (printed + logged)
# =============================
cat("\n=== (1) INPUT / PARAMETER CHECKS ===\n")
log_line("\n=== INPUT / PARAMETER CHECKS ===")

bp_std <- beta_params_from_mean_sd(p_std_mean, p_std_sd)
bp_int <- beta_params_from_mean_sd(p_int_mean, p_int_sd)
cat("Beta feasibility: PASS\n")
cat("Beta params Standard: "); print(bp_std)
cat("Beta params Intervention: "); print(bp_int)
log_line(paste0("Beta params Standard: alpha=", round(bp_std["alpha"],4), ", beta=", round(bp_std["beta"],4)))
log_line(paste0("Beta params Intervention: alpha=", round(bp_int["alpha"],4), ", beta=", round(bp_int["beta"],4)))

mE <- weibull_mean(shape_E, scale_E)
mL <- weibull_mean(shape_L, scale_L)
cat(sprintf("Weibull analytic mean survival: Early≈%.4f, Late≈%.4f\n", mE, mL))
log_line(sprintf("Weibull mean survival: Early≈%.6f, Late≈%.6f", mE, mL))
if (mE <= mL){
  cat("WARNING: Early mean survival is not higher than late with these parameters.\n")
  cat("Action: confirm parameterization/units.\n")
  log_line("WARNING: Early mean survival is not higher than late. Check parameterization/units.")
}

# =============================
# 4) Visuals of inputs (optional; kept)
# =============================
make_input_plots <- function(){
  # 4.1 Beta priors
  p_grid <- seq(0.001, 0.999, length.out=800)
  df_beta <- data.frame(
    p = rep(p_grid, 2),
    density = c(dbeta(p_grid, bp_std["alpha"], bp_std["beta"]),
                dbeta(p_grid, bp_int["alpha"], bp_int["beta"])),
    strategy = factor(rep(c("Standard","Intervention"), each=length(p_grid)))
  )
  g_beta <- ggplot(df_beta, aes(x=p, y=density, linetype=strategy)) +
    geom_line(linewidth=1) +
    labs(title="Stage assignment: Beta priors for p(early)",
         x="p(early)", y="Density", linetype=NULL) +
    theme(legend.position="right")
  ggsave(file.path(OUTDIR,"plot_beta_priors.png"), g_beta, width=8, height=4, dpi=220)
  
  # 4.2 Survival densities + KM (sanity check)
  n_demo <- 5000
  T_E <- rweibull(n_demo, shape=shape_E, scale=scale_E)
  T_L <- rweibull(n_demo, shape=shape_L, scale=scale_L)
  df_surv <- data.frame(time=c(T_E,T_L), stage=factor(rep(c("Early","Late"), each=n_demo)))
  
  x99 <- q_safe(df_surv$time, 0.99)
  g_surv_dens <- ggplot(df_surv, aes(x=time, colour=stage, fill=stage)) +
    geom_density(alpha=0.20, linewidth=0.9) +
    coord_cartesian(xlim=c(0, x99)) +
    labs(title="Survival time distributions (Weibull draws)",
         subtitle="Shown on 0–99th percentile range for readability",
         x="Time (0–99th pctile)", y="Density", colour=NULL, fill=NULL) +
    theme(legend.position="right")
  ggsave(file.path(OUTDIR,"plot_survival_weibull_density.png"), g_surv_dens, width=8, height=4, dpi=220)
  
  km_path <- file.path(OUTDIR,"plot_survival_km.png")
  km_zoom_path <- file.path(OUTDIR,"plot_survival_km_zoom.png")
  
  fit_km <- survfit(Surv(c(T_E,T_L), rep(1,2*n_demo)) ~ rep(c("Early","Late"), each=n_demo))
  
  png(km_path, width=1000, height=700, res=150)
  plot(fit_km, col=c("black","grey50"), lwd=2,
       xlab="Time", ylab="Survival probability",
       main="Kaplan–Meier curves (simulated from Weibull)")
  legend("topright", legend=c("Early","Late"), col=c("black","grey50"), lwd=2, bty="n")
  dev.off()
  
  x_zoom <- q_safe(c(T_E, T_L), 0.90)
  png(km_zoom_path, width=1000, height=700, res=150)
  plot(fit_km, col=c("black","grey50"), lwd=2,
       xlim=c(0, x_zoom),
       xlab=paste0("Time (0–90th pctile ≈ ", round(x_zoom,3), ")"),
       ylab="Survival probability",
       main="Kaplan–Meier curves (zoomed) – clearer separation")
  legend("topright", legend=c("Early","Late"), col=c("black","grey50"), lwd=2, bty="n")
  dev.off()
  
  # 4.3 Costs
  cost_E_demo <- rnorm_trunc0(n_demo, mu_E, sd_E)
  cost_L_demo <- rnorm_trunc0(n_demo, mu_L, sd_L)
  df_cost <- data.frame(cost=c(cost_E_demo,cost_L_demo),
                        stage=factor(rep(c("Early","Late"), each=n_demo)))
  g_cost <- ggplot(df_cost, aes(x=cost, fill=stage)) +
    geom_density(alpha=0.25) +
    labs(title="Costs (Normal SD=20%; truncated at 0)",
         x="Total cost (£)", y="Density", fill=NULL) +
    theme(legend.position="right")
  ggsave(file.path(OUTDIR,"plot_cost_density.png"), g_cost, width=8, height=4, dpi=220)
  
  # 4.4 QALYs
  Q_E_demo <- rexp(n_demo, rate=exp_rate_from_mean(qaly_E_mean))
  Q_L_demo <- rexp(n_demo, rate=exp_rate_from_mean(qaly_L_mean))
  df_qaly <- data.frame(qaly=c(Q_E_demo,Q_L_demo),
                        stage=factor(rep(c("Early","Late"), each=n_demo)))
  q99 <- q_safe(df_qaly$qaly, 0.99)
  g_qaly <- ggplot(df_qaly, aes(x=qaly, fill=stage)) +
    geom_density(alpha=0.25) +
    coord_cartesian(xlim=c(0,q99)) +
    labs(title="QALYs (Exponential toy model; mean-based)",
         subtitle="Shown on 0–99th percentile range for readability",
         x="QALYs (0–99th pctile)", y="Density", fill=NULL) +
    theme(legend.position="right")
  ggsave(file.path(OUTDIR,"plot_qaly_density.png"), g_qaly, width=8, height=4, dpi=220)
}

# =============================
# 5) Model engine (patient-level; includes discounting)
# =============================
simulate_strategy_patients <- function(p_mean, p_sd, add_cost=0, n_patients=N_PATIENTS){
  bp <- beta_params_from_mean_sd(p_mean, p_sd)
  p_early <- rbeta(1, bp["alpha"], bp["beta"])
  stage <- rbinom(n_patients, 1, p_early)  # 1 early, 0 late
  
  T <- numeric(n_patients)
  nE <- sum(stage==1); nL <- n_patients - nE
  if (nE>0) T[stage==1] <- rweibull(nE, shape=shape_E, scale=scale_E)
  if (nL>0) T[stage==0] <- rweibull(nL, shape=shape_L, scale=scale_L)
  
  ly_disc <- discounted_ly(T, DISC_RATE)
  
  qaly <- numeric(n_patients)
  if (nE>0) qaly[stage==1] <- rexp(nE, rate=exp_rate_from_mean(qaly_E_mean))
  if (nL>0) qaly[stage==0] <- rexp(nL, rate=exp_rate_from_mean(qaly_L_mean))
  qaly_disc <- discount_midpoint(qaly, T, DISC_RATE)
  
  cost <- numeric(n_patients)
  if (nE>0) cost[stage==1] <- rnorm_trunc0(nE, mu_E, sd_E)
  if (nL>0) cost[stage==0] <- rnorm_trunc0(nL, mu_L, sd_L)
  cost_disc <- discount_midpoint(cost, T, DISC_RATE) + add_cost
  
  data.frame(stage=stage, T=T, ly_disc=ly_disc, qaly_disc=qaly_disc, cost_disc=cost_disc, p_early=p_early)
}

# =============================
# 6) CHECKS (internal logic)
# =============================
cat("\n=== (2) INTERNAL LOGIC CHECKS ===\n")
log_line("\n=== INTERNAL LOGIC CHECKS ===")

tmp <- simulate_strategy_patients(p_mean=0.999, p_sd=0.001, add_cost=0, n_patients=2000)
share_early <- mean(tmp$stage)
cat(sprintf("Extreme early-stage test: share early=%.3f\n", share_early))
log_line(sprintf("Extreme early-stage test: share early=%.4f", share_early))
if (share_early < 0.95) stop("Extreme-case validation failed: expected mostly early.")

A <- simulate_strategy_patients(p_std_mean, p_std_sd, add_cost=0, n_patients=4000)
B <- simulate_strategy_patients(p_std_mean, p_std_sd, add_cost=0, n_patients=4000)
noeff_dC <- mean(B$cost_disc)-mean(A$cost_disc)
noeff_dQ <- mean(B$qaly_disc)-mean(A$qaly_disc)
cat(sprintf("No-effect sanity: ΔCost≈%.2f, ΔQALY≈%.4f\n", noeff_dC, noeff_dQ))
log_line(sprintf("No-effect sanity: dC≈%.4f, dQ≈%.6f", noeff_dC, noeff_dQ))

# =============================
# 7) PSA (seed reset immediately before PSA) (A)
# =============================
run_psa <- function(n_iter=PSA_ITERS, wtp=WTP){
  out <- vector("list", n_iter)
  for (i in seq_len(n_iter)){
    std <- simulate_strategy_patients(p_std_mean, p_std_sd, add_cost=0)
    int <- simulate_strategy_patients(p_int_mean, p_int_sd, add_cost=cost_intervention_fixed)
    
    mean_std <- c(cost=mean(std$cost_disc), qaly=mean(std$qaly_disc), ly=mean(std$ly_disc))
    mean_int <- c(cost=mean(int$cost_disc), qaly=mean(int$qaly_disc), ly=mean(int$ly_disc))
    
    dC <- mean_int["cost"] - mean_std["cost"]
    dQ <- mean_int["qaly"] - mean_std["qaly"]
    dLY<- mean_int["ly"]   - mean_std["ly"]
    
    ICER_iter <- ifelse(dQ>0, dC/dQ, NA_real_)
    INB  <- wtp*dQ - dC
    
    out[[i]] <- data.frame(iter=i,
                           cost_std=mean_std["cost"], qaly_std=mean_std["qaly"], ly_std=mean_std["ly"],
                           cost_int=mean_int["cost"], qaly_int=mean_int["qaly"], ly_int=mean_int["ly"],
                           dC=dC, dQ=dQ, dLY=dLY,
                           ICER_iter=ICER_iter, INB=INB)
  }
  dplyr::bind_rows(out)
}

# =============================
# 8) Main PSA run + outputs
# =============================
if (RUN_PSA_MAIN){
  cat("\nRunning PSA...\n")
  log_line("\n=== PSA RUN ===")
  log_line(paste0("Resetting seed immediately before PSA: ", SEED_FIXED))
  set.seed(SEED_FIXED)
  
  make_input_plots()
  
  psa <- run_psa()
  write.csv(psa, file.path(OUTDIR,"psa_draws.csv"), row.names=FALSE)
  
  psa <- psa %>% mutate(
    dC_cum=cummean(dC),
    dQ_cum=cummean(dQ),
    INB_cum=cummean(INB)
  )
  
  cat("\n=== (3) NUMERICAL VALIDITY: MCSE + CONVERGENCE ===\n")
  log_line("\n=== NUMERICAL VALIDITY ===")
  
  mcse_dC  <- mcse_mean(psa$dC)
  mcse_dQ  <- mcse_mean(psa$dQ)
  mcse_inb <- mcse_mean(psa$INB)
  cat(sprintf("MCSE(ΔCost) = %.2f\n", mcse_dC))
  cat(sprintf("MCSE(ΔQALY) = %.4f\n", mcse_dQ))
  cat(sprintf("MCSE(INB)   = %.2f\n", mcse_inb))
  log_line(sprintf("MCSE dC=%.6f; dQ=%.8f; INB=%.6f", mcse_dC, mcse_dQ, mcse_inb))
  
  g_conv_cost <- ggplot(psa, aes(iter, dC_cum)) + geom_line(linewidth=0.8) +
    labs(title="PSA convergence: cumulative mean ΔCost", x="PSA iteration", y="Cum. mean ΔCost (£)")
  g_conv_qaly <- ggplot(psa, aes(iter, dQ_cum)) + geom_line(linewidth=0.8) +
    labs(title="PSA convergence: cumulative mean ΔQALY", x="PSA iteration", y="Cum. mean ΔQALY")
  g_conv_inb  <- ggplot(psa, aes(iter, INB_cum)) + geom_line(linewidth=0.8) +
    labs(title=paste0("PSA convergence: cumulative mean INB (WTP=£", format(WTP, big.mark=","), ")"),
         x="PSA iteration", y="Cum. mean INB (£)")
  
  ggsave(file.path(OUTDIR,"plot_convergence_dC.png"), g_conv_cost, width=8, height=4, dpi=220)
  ggsave(file.path(OUTDIR,"plot_convergence_dQ.png"), g_conv_qaly, width=8, height=4, dpi=220)
  ggsave(file.path(OUTDIR,"plot_convergence_INB.png"), g_conv_inb,  width=8, height=4, dpi=220)
  
  # ---- (C) ICER definitions locked ----
  dC_mean <- mean(psa$dC)
  dQ_mean <- mean(psa$dQ)
  ICER_ratio_of_means <- dC_mean / dQ_mean
  ICER_mean_of_ratios <- mean(psa$ICER_iter, na.rm=TRUE)
  
  summ <- psa %>% summarise(
    cost_std_mean=mean(cost_std), qaly_std_mean=mean(qaly_std), ly_std_mean=mean(ly_std),
    cost_int_mean=mean(cost_int), qaly_int_mean=mean(qaly_int), ly_int_mean=mean(ly_int),
    dC_mean=mean(dC), dC_lo=quantile(dC,0.025), dC_hi=quantile(dC,0.975),
    dQ_mean=mean(dQ), dQ_lo=quantile(dQ,0.025), dQ_hi=quantile(dQ,0.975),
    dLY_mean=mean(dLY),
    ICER_ratio_of_means=ICER_ratio_of_means,
    ICER_mean_of_ratios=ICER_mean_of_ratios,
    p_ce=mean(INB>0)
  )
  write.csv(summ, file.path(OUTDIR,"psa_summary.csv"), row.names=FALSE)
  
  cat("\n=== PSA SUMMARY (LOCKED DEFINITIONS) ===\n")
  print(summ)
  cat(sprintf("\nWTP threshold used: £%s per QALY\n", format(WTP, big.mark=",")))
  cat(sprintf("Pr(cost-effective) at WTP: %.1f%%\n", 100*summ$p_ce))
  cat(sprintf("ICER (ratio of means) = %.2f £/QALY\n", summ$ICER_ratio_of_means))
  cat(sprintf("ICER (mean of per-iter ratios; NOT recommended as headline) = %.2f £/QALY\n", summ$ICER_mean_of_ratios))
  
  # Decision plots
  g_ce_plane <- ggplot(psa, aes(dQ, dC)) +
    geom_hline(yintercept=0, linewidth=0.4) +
    geom_vline(xintercept=0, linewidth=0.4) +
    geom_point(alpha=0.25, size=1) +
    labs(title="Cost-effectiveness plane (PSA draws)",
         x="Incremental QALYs (ΔQ)", y="Incremental Cost (£, ΔC)")
  ggsave(file.path(OUTDIR,"plot_ce_plane.png"), g_ce_plane, width=6.5, height=5, dpi=220)
  
  wtp_grid <- seq(0, 50000, by=1000)
  ceac <- data.frame(
    wtp = wtp_grid,
    p_ce = sapply(wtp_grid, function(k) mean(k*psa$dQ - psa$dC > 0))
  )
  g_ceac <- ggplot(ceac, aes(wtp, p_ce)) +
    geom_line(linewidth=1) +
    scale_y_continuous(limits=c(0,1)) +
    labs(title="Cost-effectiveness acceptability curve (CEAC)",
         x="Willingness-to-pay (£/QALY)", y="Pr(cost-effective)")
  ggsave(file.path(OUTDIR,"plot_ceac.png"), g_ceac, width=7, height=4.5, dpi=220)
  write.csv(ceac, file.path(OUTDIR,"ceac.csv"), row.names=FALSE)
  
  cat("\n=== VALIDATION CHECKLIST (printable) ===\n")
  cat("• Face validity: stage-shift structure aligns with early vs late prognosis and costs.\n")
  cat("• Parameter validity: Beta feasibility; cost truncation at 0; Weibull plausibility; QALY exponential stated as toy.\n")
  cat("• Internal validity: extreme-case + no-effect sanity checks.\n")
  cat("• Numerical validity: MCSE + convergence plots.\n")
  cat("• External validity: benchmark mean outcomes vs literature when available.\n")
  
  cat("\n=== OUTPUT LOCATION ===\n")
  cat("All results saved in:\n", OUTDIR, "\n")
  
  
  icer_label <- function(dC, dQ){
    if (is.na(dC) || is.na(dQ)) return("NA")
    if (dQ > 0 && dC < 0) return("Dominant (↓Cost, ↑QALY)")
    if (dQ < 0 && dC > 0) return("Dominated (↑Cost, ↓QALY)")
    if (abs(dQ) < 1e-8)   return("Undefined (ΔQ≈0)")
    paste0(round(dC/dQ, 2), " £/QALY")
  }
  
  log_line("\n=== OUTPUTS WRITTEN ===")
  log_line(OUTDIR)
  log_line("inputs_audit.csv; psa_draws.csv; psa_summary.csv; ceac.csv")
  log_line("plot_beta_priors.png; plot_survival_weibull_density.png; plot_survival_km.png; plot_survival_km_zoom.png")
  log_line("plot_cost_density.png; plot_qaly_density.png; plot_convergence_dC.png; plot_convergence_dQ.png; plot_convergence_INB.png")
  log_line("plot_ce_plane.png; plot_ceac.png")
}

# ==========================================================
# 9) R-ONLY ML EMULATOR: dataset generation + training + predict
# ==========================================================

# ---- Emulator design choices ----
# We learn: inputs (parameters) -> outputs (dC_mean, dQ_mean, p_ce)
# Then derive: INMB and ICER safely from predicted dC/dQ.
#
# You can change parameter ranges below. v1 uses bounded multiplicative jitter.

# ---------- EMULATOR SPEED (for dataset generation only) ----------
# You can keep your main PSA at 1000/2000, but for emulator training rows,
# it’s often fine to use smaller settings for speed.
EMULATOR_N_PATIENTS <- 600
EMULATOR_PSA_ITERS  <- 800

# Base params as a list (from locked inputs)
base_params <- list(
  # run settings
  N_PATIENTS = N_PATIENTS,
  PSA_ITERS  = PSA_ITERS,
  WTP        = WTP,
  DISC_RATE  = DISC_RATE,
  
  # stage shift
  p_std_mean = p_std_mean,
  p_std_sd   = p_std_sd,
  p_int_mean = p_int_mean,
  p_int_sd   = p_int_sd,
  
  # survival
  shape_E = shape_E, scale_E = scale_E,
  shape_L = shape_L, scale_L = scale_L,
  
  # costs
  mu_E = mu_E, sd_E = sd_E,
  mu_L = mu_L, sd_L = sd_L,
  cost_intervention_fixed = cost_intervention_fixed,
  
  # qalys
  qaly_E_mean = qaly_E_mean,
  qaly_L_mean = qaly_L_mean
)

# Parameterized engine (uses params list instead of globals)
simulate_strategy_patients_param <- function(params, p_mean, p_sd, add_cost=0){
  with(params, {
    bp <- beta_params_from_mean_sd(p_mean, p_sd)
    p_early <- rbeta(1, bp["alpha"], bp["beta"])
    stage <- rbinom(N_PATIENTS, 1, p_early)
    
    T <- numeric(N_PATIENTS)
    nE <- sum(stage==1); nL <- N_PATIENTS - nE
    if (nE>0) T[stage==1] <- rweibull(nE, shape=shape_E, scale=scale_E)
    if (nL>0) T[stage==0] <- rweibull(nL, shape=shape_L, scale=scale_L)
    
    ly_disc <- discounted_ly(T, DISC_RATE)
    
    qaly <- numeric(N_PATIENTS)
    if (nE>0) qaly[stage==1] <- rexp(nE, rate=exp_rate_from_mean(qaly_E_mean))
    if (nL>0) qaly[stage==0] <- rexp(nL, rate=exp_rate_from_mean(qaly_L_mean))
    qaly_disc <- discount_midpoint(qaly, T, DISC_RATE)
    
    cost <- numeric(N_PATIENTS)
    if (nE>0) cost[stage==1] <- rnorm_trunc0(nE, mu_E, sd_E)
    if (nL>0) cost[stage==0] <- rnorm_trunc0(nL, mu_L, sd_L)
    cost_disc <- discount_midpoint(cost, T, DISC_RATE) + add_cost
    
    data.frame(qaly_disc=qaly_disc, cost_disc=cost_disc, ly_disc=ly_disc)
  })
}

run_psa_param <- function(params){
  with(params, {
    out_dC  <- numeric(PSA_ITERS)
    out_dQ  <- numeric(PSA_ITERS)
    out_INB <- numeric(PSA_ITERS)
    
    for (i in seq_len(PSA_ITERS)){
      std <- simulate_strategy_patients_param(params, p_std_mean, p_std_sd, add_cost=0)
      int <- simulate_strategy_patients_param(params, p_int_mean, p_int_sd, add_cost=cost_intervention_fixed)
      
      dC <- mean(int$cost_disc) - mean(std$cost_disc)
      dQ <- mean(int$qaly_disc) - mean(std$qaly_disc)
      
      out_dC[i]  <- dC
      out_dQ[i]  <- dQ
      out_INB[i] <- WTP*dQ - dC
    }
    
    data.frame(
      dC_mean=mean(out_dC),
      dQ_mean=mean(out_dQ),
      p_ce=mean(out_INB > 0),
      mcse_dC=mcse_mean(out_dC),
      mcse_dQ=mcse_mean(out_dQ)
    )
  })
}

# Scenario sampler (bounded jitter)
sample_params_v1 <- function(base){
  p <- base
  jitter <- function(x, frac=0.20) x * runif(1, 1-frac, 1+frac)
  clamp01 <- function(x) max(0.01, min(0.99, x))
  
  # vary stage means; keep SD proportional and feasible
  p$p_std_mean <- clamp01(jitter(p$p_std_mean, 0.15))
  p$p_int_mean <- clamp01(jitter(p$p_int_mean, 0.15))
  p$p_std_sd <- 0.10 * p$p_std_mean
  p$p_int_sd <- 0.10 * p$p_int_mean
  
  # survival
  p$shape_E <- max(0.05, jitter(p$shape_E, 0.25))
  p$scale_E <- max(1e-6, jitter(p$scale_E, 0.25))
  p$shape_L <- max(0.05, jitter(p$shape_L, 0.25))
  p$scale_L <- max(1e-6, jitter(p$scale_L, 0.25))
  
  # costs
  p$mu_E <- max(0, jitter(p$mu_E, 0.25)); p$sd_E <- 0.20 * p$mu_E
  p$mu_L <- max(0, jitter(p$mu_L, 0.25)); p$sd_L <- 0.20 * p$mu_L
  p$cost_intervention_fixed <- max(0, jitter(p$cost_intervention_fixed, 0.35))
  
  # qalys
  p$qaly_E_mean <- max(1e-3, jitter(p$qaly_E_mean, 0.25))
  p$qaly_L_mean <- max(1e-3, jitter(p$qaly_L_mean, 0.25))
  
  # discount rate
  p$DISC_RATE <- max(0, min(0.10, jitter(p$DISC_RATE, 0.40)))
  
  p
}

generate_emulator_dataset <- function(n_scenarios=2000, out_csv="emulator_training.csv",
                                      seed=SEED_FIXED, speed_mode=TRUE){
  set.seed(seed)
  rows <- vector("list", n_scenarios)
  
  for (s in seq_len(n_scenarios)){
    params <- sample_params_v1(base_params)
    
    # speed settings for emulator dataset only
    if (speed_mode){
      params$N_PATIENTS <- EMULATOR_N_PATIENTS
      params$PSA_ITERS  <- EMULATOR_PSA_ITERS
    }
    
    # reproducibility per scenario
    set.seed(seed + s)
    
    # Optional sanity: survival ordering (log only; do not stop unless you want)
    mE_s <- weibull_mean(params$shape_E, params$scale_E)
    mL_s <- weibull_mean(params$shape_L, params$scale_L)
    invalid_surv <- as.integer(mE_s <= mL_s)
    
    res <- run_psa_param(params)
    
    x <- as.data.frame(params)
    rows[[s]] <- cbind(
      scenario_id=s,
      invalid_survival_order=invalid_surv,
      x, res
    )
    
    if (s %% 50 == 0) message("Emulator scenarios: ", s, "/", n_scenarios)
  }
  
  df <- dplyr::bind_rows(rows)
  write.csv(df, file.path(OUTDIR, out_csv), row.names=FALSE)
  df
}

# ---------- Emulator training (xgboost) ----------
train_emulator_xgb <- function(train_csv=file.path(OUTDIR,"emulator_training.csv"),
                               out_prefix=file.path(OUTDIR,"emulator_model"),
                               seed=SEED_FIXED){
  # Require xgboost
  if (!requireNamespace("xgboost", quietly = TRUE)) {
    stop("Package 'xgboost' not installed. Install with: install.packages('xgboost')")
  }
  
  df <- read.csv(train_csv)
  
  # Targets
  targets <- c("dC_mean","dQ_mean","p_ce")
  leakage <- c("mcse_dC","mcse_dQ")   # NOT true inputs; remove from features
  drop_cols <- c("scenario_id", targets, leakage)
  
  X <- df[, setdiff(names(df), drop_cols), drop=FALSE]
  
  
  # Ensure numeric matrix
  Xmat <- as.matrix(X)
  yC <- df$dC_mean
  yQ <- df$dQ_mean
  yP <- df$p_ce
  
  set.seed(seed)
  idx <- sample(seq_len(nrow(df)), size=floor(0.8*nrow(df)))
  
  X_train <- Xmat[idx, , drop=FALSE]
  X_test  <- Xmat[-idx, , drop=FALSE]
  
  # Common params
  params_reg <- list(
    objective="reg:squarederror",
    eta=0.05,
    max_depth=5,
    subsample=0.9,
    colsample_bytree=0.9
  )
  
  dtrainC <- xgboost::xgb.DMatrix(X_train, label=yC[idx])
  dtestC  <- xgboost::xgb.DMatrix(X_test,  label=yC[-idx])
  mC <- xgboost::xgb.train(params=params_reg, data=dtrainC, nrounds=600, verbose=0)
  predC <- predict(mC, dtestC)
  maeC <- mean(abs(yC[-idx] - predC))
  
  dtrainQ <- xgboost::xgb.DMatrix(X_train, label=yQ[idx])
  dtestQ  <- xgboost::xgb.DMatrix(X_test,  label=yQ[-idx])
  mQ <- xgboost::xgb.train(params=params_reg, data=dtrainQ, nrounds=600, verbose=0)
  predQ <- predict(mQ, dtestQ)
  maeQ <- mean(abs(yQ[-idx] - predQ))
  
  dtrainP <- xgboost::xgb.DMatrix(X_train, label=yP[idx])
  dtestP  <- xgboost::xgb.DMatrix(X_test,  label=yP[-idx])
  mP <- xgboost::xgb.train(params=params_reg, data=dtrainP, nrounds=500, verbose=0)
  predP <- pmin(1, pmax(0, predict(mP, dtestP)))
  maeP <- mean(abs(yP[-idx] - predP))
  
  # Save models + feature names
  saveRDS(list(model=mC, features=colnames(Xmat), metrics=list(MAE=maeC)),
          paste0(out_prefix,"_dC.rds"))
  saveRDS(list(model=mQ, features=colnames(Xmat), metrics=list(MAE=maeQ)),
          paste0(out_prefix,"_dQ.rds"))
  saveRDS(list(model=mP, features=colnames(Xmat), metrics=list(MAE=maeP)),
          paste0(out_prefix,"_pCE.rds"))
  
  cat("\n=== Emulator training complete (xgboost) ===\n")
  cat(sprintf("MAE(dC_mean)=%.3f\n", maeC))
  cat(sprintf("MAE(dQ_mean)=%.5f\n", maeQ))
  cat(sprintf("MAE(p_ce)  =%.4f\n", maeP))
  invisible(list(MAE_dC=maeC, MAE_dQ=maeQ, MAE_pCE=maeP))
}

predict_emulator <- function(params_list,
                             model_prefix=file.path(OUTDIR,"emulator_model")){
  if (!requireNamespace("xgboost", quietly = TRUE)) {
    stop("Package 'xgboost' not installed. Install with: install.packages('xgboost')")
  }
  
  mC <- readRDS(paste0(model_prefix,"_dC.rds"))
  mQ <- readRDS(paste0(model_prefix,"_dQ.rds"))
  mP <- readRDS(paste0(model_prefix,"_pCE.rds"))
  
  # Build 1-row data frame; include invalid_survival_order if you want (default 0)
  df <- as.data.frame(params_list)
  if (!"invalid_survival_order" %in% names(df)) df$invalid_survival_order <- 0
  
  # Ensure all features exist
  missing <- setdiff(mC$features, names(df))
  if (length(missing) > 0){
    stop("Missing emulator input fields: ", paste(missing, collapse=", "))
  }
  
  X <- as.matrix(df[, mC$features, drop=FALSE])
  Xm <- xgboost::xgb.DMatrix(X)
  
  dC <- as.numeric(predict(mC$model, Xm))
  dQ <- as.numeric(predict(mQ$model, Xm))
  p_ce <- as.numeric(predict(mP$model, Xm))
  p_ce <- max(0, min(1, p_ce))
  
  WTP_use <- df$WTP
  inmb <- WTP_use*dQ - dC
  
  icer <- NA_real_
  if (abs(dQ) > 1e-8) icer <- dC/dQ
  
  list(dC_mean=dC, dQ_mean=dQ, INMB=inmb, p_ce=p_ce, ICER=icer)
}

# =============================
# 10) Run emulator steps (if toggled)
# =============================
if (RUN_EMULATOR_DATASET){
  cat("\n=== Generating emulator dataset ===\n")
  # Tip: start with 300 scenarios to validate pipeline quickly
  df_em <- generate_emulator_dataset(
    n_scenarios = 300,
    out_csv = "emulator_training.csv",
    seed = SEED_FIXED,
    speed_mode = TRUE
  )
  cat("Emulator dataset written to:\n", file.path(OUTDIR,"emulator_training.csv"), "\n")
  cat("Rows:", nrow(df_em), "\n")
}

if (RUN_EMULATOR_TRAIN){
  cat("\n=== Training emulator models (xgboost) ===\n")
  train_emulator_xgb(
    train_csv = file.path(OUTDIR,"emulator_training.csv"),
    out_prefix = file.path(OUTDIR,"emulator_model"),
    seed = SEED_FIXED
  )
  cat("Models saved with prefix:\n", file.path(OUTDIR,"emulator_model"), "\n")
}

if (RUN_EMULATOR_DEMO_PREDICT){
  cat("\n=== Emulator demo prediction (base params) ===\n")
  demo_params <- base_params
  # Use same speed settings? For emulator inference it doesn’t matter; these are just features.
  demo_params$N_PATIENTS <- EMULATOR_N_PATIENTS
  demo_params$PSA_ITERS  <- EMULATOR_PSA_ITERS
  demo_params$invalid_survival_order <- as.integer(weibull_mean(demo_params$shape_E, demo_params$scale_E) <=
                                                     weibull_mean(demo_params$shape_L, demo_params$scale_L))
  pred <- predict_emulator(demo_params, model_prefix=file.path(OUTDIR,"emulator_model"))
  print(pred)
}

# =============================
# 11) Optional Plumber API (single-file)
# =============================
if (RUN_PLUMBER_API){
  if (!requireNamespace("plumber", quietly = TRUE)) {
    stop("Package 'plumber' not installed. Install with: install.packages('plumber')")
  }
  if (!requireNamespace("jsonlite", quietly = TRUE)) {
    stop("Package 'jsonlite' not installed. Install with: install.packages('jsonlite')")
  }
  
  # Create a plumber router in-memory (still single-file)
  pr <- plumber::pr()
  
  pr$handle("POST", "/predict", function(req, res){
    params <- jsonlite::fromJSON(req$postBody)
    # ensure list (not data.frame)
    if (is.data.frame(params)) params <- as.list(params)
    out <- predict_emulator(params, model_prefix=file.path(OUTDIR,"emulator_model"))
    res$setHeader("Content-Type", "application/json")
    jsonlite::toJSON(out, auto_unbox = TRUE)
  })
  
  cat("\nPlumber API running at http://127.0.0.1:8000/predict\n")
  cat("POST JSON body with fields matching emulator features.\n")
  pr$run(host="127.0.0.1", port=8000)
}

############################################################
# End of script
############################################################
